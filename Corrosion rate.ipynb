{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI model-1 (pH & H2O)-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 原始數據匯入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先把mpy.csv的data匯入，使用numpy矩陣型態\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "np.set_printoptions(suppress=True)\n",
    "pph = pd.read_csv('C:/Users/bigje/Desktop/predict-PH-H2O.csv',\n",
    "                 index_col=0,\n",
    "                 parse_dates=True,\n",
    "                 encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 數據切割：切割15%的驗證數據並儲存成.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#random_state隨意給定，主要是讓每次抽樣都是隨機不一樣的。\n",
    "#test_size只測試資料占比多少\n",
    "x_train, x_test, y_train, y_test = train_test_split(pph.loc[:, ['Feed', 'H2O', 'HCL', 'LPG', 'C4']], \n",
    "                                                    pph.loc[:, ['H2O-float', 'pH']], \n",
    "                                                    test_size=0.15,\n",
    "                                                    random_state = 87)\n",
    "#var的Data'x & y合併(pd.concat用在欄位合併)\n",
    "xy_var = pd.concat([x_test, y_test], axis=1)\n",
    "# #儲存驗證集檔案\n",
    "# xy_var.to_csv('C:/Users/bigje/Desktop/(py)var15%.csv')\n",
    "#85%的資料 x&y合併\n",
    "xy_train = pd.concat([x_train, y_train], axis=1)\n",
    "# #儲存起來\n",
    "# xy_train.to_csv('C:/Users/bigje/Desktop/(py)train85%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #檢查分割出來的訓練與測試資料的筆數\n",
    "# print(len(x_train), len(y_train), len(x_test), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 再將剩餘的85%數據，切割成80/20的訓練集與測試集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_train, \n",
    "                                                    y_train, \n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state = 87)\n",
    "#print(len(x_train), len(y_train), len(x_test), len(y_test))\n",
    "#train合併、test合併\n",
    "xy_train = pd.concat([x_train, y_train], axis=1)\n",
    "xy_test = pd.concat([x_test, y_test], axis=1)\n",
    "# #儲存訓練集與測試集\n",
    "# xy_train.to_csv('C:/Users/bigje/Desktop/(py)train80%.csv')\n",
    "# xy_test.to_csv('C:/Users/bigje/Desktop/(py)test20%.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #若不在重新抽樣可叫出先前抽樣的資料\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# x_train = pd.read_csv('C:/Users/bigje/Desktop/FCFC-chem1/FCFC-chem1-data-csv/(py)train80%.csv',\n",
    "#                  index_col=0,\n",
    "#                  parse_dates=True,\n",
    "#                  encoding='latin-1')\n",
    "# y_train = x_train.loc[:, ['H2O-float', 'pH']]\n",
    "# x_train = x_train.loc[:,['Feed', 'H2O', 'HCL', 'LPG', 'C4']]\n",
    "\n",
    "# x_test = pd.read_csv('C:/Users/bigje/Desktop/FCFC-chem1/FCFC-chem1-data-csv/(py)test20%.csv',\n",
    "#                  index_col=0,\n",
    "#                  parse_dates=True,\n",
    "#                  encoding='latin-1')\n",
    "# y_test = x_test.loc[:, ['H2O-float', 'pH']]\n",
    "# x_test = x_test.loc[:, ['Feed', 'H2O', 'HCL', 'LPG', 'C4']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 轉成np格式，於Keras NN中需用矩陣型態"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npx_train = x_train.to_numpy() #x轉成np格式\n",
    "npy_train = y_train.to_numpy() #y轉乘np格式\n",
    "npx_test = x_test.to_numpy()\n",
    "npy_test = y_test.to_numpy()\n",
    "type(npx_train)\n",
    "# print(npx_train)\n",
    "# print(npy_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將np下的自變數與依變數存成pkl，以便還原正規化後的預測值使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/bigje/Desktop/minmax-y.pkl']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(npx_train, 'C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/minmax-x.pkl')\n",
    "joblib.dump(npy_train, 'C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/minmax-y.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 將數值都正規化(min-max)(0~1之間)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "#訓練與測試的x&y正規化需分開設定\n",
    "trainx = preprocessing.MinMaxScaler()\n",
    "trainy = preprocessing.MinMaxScaler()\n",
    "testx = preprocessing.MinMaxScaler()\n",
    "testy = preprocessing.MinMaxScaler()\n",
    "\n",
    "#fit_transform()為正規化(0~1之間)\n",
    "trainx_minmax = trainx.fit_transform(npx_train).reshape(npx_train.shape[0],npx_train.shape[1])\n",
    "trainy_minmax = trainy.fit_transform(npy_train).reshape(npy_train.shape[0],npy_train.shape[1])\n",
    "testx_minmax = testx.fit_transform(npx_test).reshape(npx_test.shape[0],npx_test.shape[1])\n",
    "testy_minmax = testy.fit_transform(npy_test).reshape(npy_test.shape[0],npy_test.shape[1])\n",
    "# print(trainx_minmax)\n",
    "# print(trainy_minmax)\n",
    "#正規化的訓練集&測試集\n",
    "x_training = trainx_minmax\n",
    "y_training = trainy_minmax\n",
    "x_testing = testx_minmax\n",
    "y_testing = testy_minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 先安裝Keras，需與tensorflow(2.2以上(含))版本匹配"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#開始導入keras模型\n",
    "from keras.models import Sequential\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense\n",
    "\n",
    "model.add(Dense(units=128, activation='relu', input_dim=5, kernel_initializer='he_normal'))\n",
    "model.add(Dense(units=128, activation='relu', kernel_initializer='he_normal'))\n",
    "model.add(Dense(units=2, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.optimizers import adam\n",
    "#loss function ：L2\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               768       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 17,538\n",
      "Trainable params: 17,538\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#查看Keras類神經模型有幾層跟詳細架構\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 0.0100 - accuracy: 0.8844\n",
      "Epoch 2/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9635\n",
      "Epoch 3/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.2905e-04 - accuracy: 0.9757\n",
      "Epoch 4/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.1901e-04 - accuracy: 0.9814\n",
      "Epoch 5/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.6580e-04 - accuracy: 0.9865\n",
      "Epoch 6/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.1864e-04 - accuracy: 0.9858\n",
      "Epoch 7/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.6102e-04 - accuracy: 0.9876\n",
      "Epoch 8/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.5138e-04 - accuracy: 0.9863\n",
      "Epoch 9/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.4208e-04 - accuracy: 0.9883\n",
      "Epoch 10/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.2736e-04 - accuracy: 0.9881\n",
      "Epoch 11/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.5249e-04 - accuracy: 0.9883\n",
      "Epoch 12/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.1877e-04 - accuracy: 0.9894\n",
      "Epoch 13/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.3273e-04 - accuracy: 0.9860\n",
      "Epoch 14/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.3133e-04 - accuracy: 0.9892\n",
      "Epoch 15/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0702e-04 - accuracy: 0.9898\n",
      "Epoch 16/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.1248e-04 - accuracy: 0.9872\n",
      "Epoch 17/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.6224e-05 - accuracy: 0.9903\n",
      "Epoch 18/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.0751e-04 - accuracy: 0.9872\n",
      "Epoch 19/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.9715e-05 - accuracy: 0.9912\n",
      "Epoch 20/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 8.2219e-05 - accuracy: 0.9900\n",
      "Epoch 21/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.7699e-05 - accuracy: 0.9903\n",
      "Epoch 22/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.6474e-05 - accuracy: 0.9876\n",
      "Epoch 23/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.2631e-05 - accuracy: 0.9896\n",
      "Epoch 24/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.7118e-05 - accuracy: 0.9883\n",
      "Epoch 25/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.5344e-05 - accuracy: 0.9927: 0s - loss: 5.5125e-05 - accuracy: 0.99\n",
      "Epoch 26/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.5406e-05 - accuracy: 0.9905\n",
      "Epoch 27/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.0784e-05 - accuracy: 0.9912: 0s - loss: 7.1500e-05 - accuracy\n",
      "Epoch 28/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.1926e-05 - accuracy: 0.9912\n",
      "Epoch 29/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.3885e-05 - accuracy: 0.9920\n",
      "Epoch 30/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.5175e-05 - accuracy: 0.9914\n",
      "Epoch 31/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.4430e-05 - accuracy: 0.9918\n",
      "Epoch 32/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3919e-05 - accuracy: 0.9900\n",
      "Epoch 33/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.4965e-05 - accuracy: 0.9934\n",
      "Epoch 34/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0187e-05 - accuracy: 0.9945\n",
      "Epoch 35/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.6657e-05 - accuracy: 0.9929\n",
      "Epoch 36/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.0666e-05 - accuracy: 0.9905\n",
      "Epoch 37/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7002e-05 - accuracy: 0.9918\n",
      "Epoch 38/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.7548e-05 - accuracy: 0.9929\n",
      "Epoch 39/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.1401e-05 - accuracy: 0.9914\n",
      "Epoch 40/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.8382e-05 - accuracy: 0.9934\n",
      "Epoch 41/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3199e-05 - accuracy: 0.9934\n",
      "Epoch 42/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.2156e-05 - accuracy: 0.9947\n",
      "Epoch 43/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.7697e-05 - accuracy: 0.9953\n",
      "Epoch 44/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9700e-05 - accuracy: 0.9927\n",
      "Epoch 45/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5891e-05 - accuracy: 0.9929\n",
      "Epoch 46/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9074e-05 - accuracy: 0.9914\n",
      "Epoch 47/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.3538e-05 - accuracy: 0.9942\n",
      "Epoch 48/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.8684e-05 - accuracy: 0.9922\n",
      "Epoch 49/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.3872e-05 - accuracy: 0.9951\n",
      "Epoch 50/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9977e-05 - accuracy: 0.9918\n",
      "Epoch 51/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2169e-05 - accuracy: 0.9942\n",
      "Epoch 52/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.2997e-05 - accuracy: 0.9938\n",
      "Epoch 53/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.5539e-05 - accuracy: 0.9942\n",
      "Epoch 54/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.5382e-05 - accuracy: 0.9934\n",
      "Epoch 55/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.1199e-05 - accuracy: 0.9931\n",
      "Epoch 56/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.5096e-05 - accuracy: 0.9936\n",
      "Epoch 57/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4871e-05 - accuracy: 0.9934\n",
      "Epoch 58/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.7678e-05 - accuracy: 0.9938\n",
      "Epoch 59/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7213e-05 - accuracy: 0.9956\n",
      "Epoch 60/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4245e-05 - accuracy: 0.9925\n",
      "Epoch 61/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9002e-05 - accuracy: 0.9960\n",
      "Epoch 62/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.9083e-05 - accuracy: 0.9958\n",
      "Epoch 63/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.2709e-05 - accuracy: 0.9945\n",
      "Epoch 64/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.1019e-05 - accuracy: 0.9936\n",
      "Epoch 65/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.3395e-05 - accuracy: 0.9954\n",
      "Epoch 66/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.4194e-05 - accuracy: 0.9954\n",
      "Epoch 67/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.9890e-05 - accuracy: 0.9934\n",
      "Epoch 68/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.6965e-05 - accuracy: 0.9951\n",
      "Epoch 69/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.2372e-05 - accuracy: 0.9936\n",
      "Epoch 70/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.6933e-05 - accuracy: 0.9931\n",
      "Epoch 71/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.3807e-05 - accuracy: 0.9951\n",
      "Epoch 72/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.3187e-05 - accuracy: 0.9940\n",
      "Epoch 73/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.3696e-05 - accuracy: 0.9951\n",
      "Epoch 74/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.5177e-05 - accuracy: 0.9951\n",
      "Epoch 75/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.0856e-05 - accuracy: 0.9951\n",
      "Epoch 76/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7210e-05 - accuracy: 0.9938\n",
      "Epoch 77/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.4058e-05 - accuracy: 0.9954\n",
      "Epoch 78/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2436e-05 - accuracy: 0.9938\n",
      "Epoch 79/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.8968e-05 - accuracy: 0.9947\n",
      "Epoch 80/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4892e-05 - accuracy: 0.9951\n",
      "Epoch 81/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7566e-05 - accuracy: 0.9958\n",
      "Epoch 82/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.3393e-05 - accuracy: 0.9954\n",
      "Epoch 83/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4636e-05 - accuracy: 0.9969\n",
      "Epoch 84/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.5670e-05 - accuracy: 0.9942\n",
      "Epoch 85/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.8654e-05 - accuracy: 0.9947\n",
      "Epoch 86/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4421e-05 - accuracy: 0.9958\n",
      "Epoch 87/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.6421e-05 - accuracy: 0.9958\n",
      "Epoch 88/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4087e-05 - accuracy: 0.9956\n",
      "Epoch 89/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.3877e-05 - accuracy: 0.9954\n",
      "Epoch 90/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.6629e-05 - accuracy: 0.9949: 0s - loss: 1.5447e-05 - accuracy\n",
      "Epoch 91/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7249e-05 - accuracy: 0.9942\n",
      "Epoch 92/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.0000e-05 - accuracy: 0.9956\n",
      "Epoch 93/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.2321e-05 - accuracy: 0.9962\n",
      "Epoch 94/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.8103e-05 - accuracy: 0.9934\n",
      "Epoch 95/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7251e-05 - accuracy: 0.9947\n",
      "Epoch 96/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.7957e-05 - accuracy: 0.9951\n",
      "Epoch 97/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.3250e-05 - accuracy: 0.9953\n",
      "Epoch 98/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.0955e-05 - accuracy: 0.9956\n",
      "Epoch 99/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.5485e-05 - accuracy: 0.9954\n",
      "Epoch 100/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.4149e-05 - accuracy: 0.9940\n",
      "Epoch 101/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.1209e-05 - accuracy: 0.9958\n",
      "Epoch 102/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0561e-05 - accuracy: 0.9964\n",
      "Epoch 103/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.4110e-05 - accuracy: 0.9951\n",
      "Epoch 104/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.1446e-05 - accuracy: 0.9960\n",
      "Epoch 105/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0940e-05 - accuracy: 0.9953: 0s - loss: 1.1692e-05 - accuracy: \n",
      "Epoch 106/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.2746e-05 - accuracy: 0.9965\n",
      "Epoch 107/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.7356e-05 - accuracy: 0.9945\n",
      "Epoch 108/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.7837e-06 - accuracy: 0.9960\n",
      "Epoch 109/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4687e-05 - accuracy: 0.9947\n",
      "Epoch 110/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0249e-05 - accuracy: 0.9964\n",
      "Epoch 111/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.9435e-06 - accuracy: 0.9953\n",
      "Epoch 112/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.4190e-06 - accuracy: 0.9958\n",
      "Epoch 113/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4540e-05 - accuracy: 0.9953\n",
      "Epoch 114/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.1650e-05 - accuracy: 0.9960\n",
      "Epoch 115/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.9232e-06 - accuracy: 0.9962\n",
      "Epoch 116/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.0826e-06 - accuracy: 0.9962\n",
      "Epoch 117/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.1535e-05 - accuracy: 0.9969\n",
      "Epoch 118/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1937e-05 - accuracy: 0.9943\n",
      "Epoch 119/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.0938e-06 - accuracy: 0.9951\n",
      "Epoch 120/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.7322e-06 - accuracy: 0.9964: 0s - loss: 7.9920e-06 \n",
      "Epoch 121/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.8766e-06 - accuracy: 0.9954\n",
      "Epoch 122/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4620e-05 - accuracy: 0.9958\n",
      "Epoch 123/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.8046e-06 - accuracy: 0.9960: 0s - loss: 1.1405e-05 - \n",
      "Epoch 124/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.5629e-06 - accuracy: 0.9958\n",
      "Epoch 125/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.3424e-06 - accuracy: 0.9956\n",
      "Epoch 126/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.7748e-06 - accuracy: 0.9954\n",
      "Epoch 127/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.9406e-06 - accuracy: 0.9958\n",
      "Epoch 128/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0576e-05 - accuracy: 0.9969\n",
      "Epoch 129/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.3641e-05 - accuracy: 0.9958\n",
      "Epoch 130/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.4233e-06 - accuracy: 0.9964\n",
      "Epoch 131/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.1449e-05 - accuracy: 0.9960\n",
      "Epoch 132/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.0161e-06 - accuracy: 0.9978\n",
      "Epoch 133/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.4471e-06 - accuracy: 0.9942\n",
      "Epoch 134/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.0769e-06 - accuracy: 0.9965\n",
      "Epoch 135/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.1216e-06 - accuracy: 0.9951\n",
      "Epoch 136/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.9911e-06 - accuracy: 0.9956\n",
      "Epoch 137/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7163e-05 - accuracy: 0.9947\n",
      "Epoch 138/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.3867e-06 - accuracy: 0.9962\n",
      "Epoch 139/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.4329e-06 - accuracy: 0.9967\n",
      "Epoch 140/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4569e-05 - accuracy: 0.9947\n",
      "Epoch 141/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.8317e-06 - accuracy: 0.9960\n",
      "Epoch 142/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.2663e-06 - accuracy: 0.9973\n",
      "Epoch 143/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.7158e-06 - accuracy: 0.9964\n",
      "Epoch 144/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.6805e-05 - accuracy: 0.9933\n",
      "Epoch 145/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.7098e-06 - accuracy: 0.9967\n",
      "Epoch 146/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.8261e-06 - accuracy: 0.9964\n",
      "Epoch 147/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.4492e-06 - accuracy: 0.9954\n",
      "Epoch 148/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.4136e-06 - accuracy: 0.9962\n",
      "Epoch 149/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.1361e-06 - accuracy: 0.9973\n",
      "Epoch 150/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.1778e-06 - accuracy: 0.9960\n",
      "Epoch 151/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.1442e-06 - accuracy: 0.9954\n",
      "Epoch 152/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 1s 3ms/step - loss: 9.7419e-06 - accuracy: 0.9956\n",
      "Epoch 153/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.2516e-06 - accuracy: 0.9964\n",
      "Epoch 154/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.1558e-06 - accuracy: 0.9969\n",
      "Epoch 155/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.1263e-05 - accuracy: 0.9942\n",
      "Epoch 156/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.1704e-05 - accuracy: 0.9953\n",
      "Epoch 157/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.3674e-06 - accuracy: 0.9945\n",
      "Epoch 158/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.8458e-06 - accuracy: 0.9960\n",
      "Epoch 159/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.2401e-06 - accuracy: 0.9967\n",
      "Epoch 160/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0256e-05 - accuracy: 0.9949\n",
      "Epoch 161/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.9865e-06 - accuracy: 0.9949\n",
      "Epoch 162/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.5217e-06 - accuracy: 0.9969\n",
      "Epoch 163/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.5997e-06 - accuracy: 0.9956\n",
      "Epoch 164/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.0484e-06 - accuracy: 0.9958\n",
      "Epoch 165/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.1133e-05 - accuracy: 0.9956\n",
      "Epoch 166/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.6974e-06 - accuracy: 0.9964: 0s - loss: 5.3944e-06 - accura\n",
      "Epoch 167/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0855e-05 - accuracy: 0.9949\n",
      "Epoch 168/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.4328e-06 - accuracy: 0.9958\n",
      "Epoch 169/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.3166e-06 - accuracy: 0.9954\n",
      "Epoch 170/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.6801e-06 - accuracy: 0.9969\n",
      "Epoch 171/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.4768e-06 - accuracy: 0.9964\n",
      "Epoch 172/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.7689e-06 - accuracy: 0.9969\n",
      "Epoch 173/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.0790e-06 - accuracy: 0.9942\n",
      "Epoch 174/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.2321e-06 - accuracy: 0.9973\n",
      "Epoch 175/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.5980e-06 - accuracy: 0.9974\n",
      "Epoch 176/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 9.4602e-06 - accuracy: 0.9964\n",
      "Epoch 177/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.9310e-06 - accuracy: 0.9965\n",
      "Epoch 178/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7838e-06 - accuracy: 0.9960\n",
      "Epoch 179/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.6257e-06 - accuracy: 0.9953\n",
      "Epoch 180/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.3507e-06 - accuracy: 0.9965\n",
      "Epoch 181/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.0143e-06 - accuracy: 0.9958\n",
      "Epoch 182/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.3878e-06 - accuracy: 0.9960\n",
      "Epoch 183/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.0666e-06 - accuracy: 0.9958\n",
      "Epoch 184/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.9166e-06 - accuracy: 0.9960\n",
      "Epoch 185/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.6841e-06 - accuracy: 0.9965\n",
      "Epoch 186/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.6320e-06 - accuracy: 0.9967\n",
      "Epoch 187/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.5683e-06 - accuracy: 0.9964\n",
      "Epoch 188/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.5134e-06 - accuracy: 0.9958\n",
      "Epoch 189/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.1641e-06 - accuracy: 0.9962\n",
      "Epoch 190/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.2089e-06 - accuracy: 0.9976\n",
      "Epoch 191/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.3322e-06 - accuracy: 0.9964\n",
      "Epoch 192/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.4764e-06 - accuracy: 0.9965\n",
      "Epoch 193/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.5324e-06 - accuracy: 0.9960\n",
      "Epoch 194/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4867e-06 - accuracy: 0.9973\n",
      "Epoch 195/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.4475e-06 - accuracy: 0.9960\n",
      "Epoch 196/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.2399e-06 - accuracy: 0.9985\n",
      "Epoch 197/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.7100e-06 - accuracy: 0.9953: 0s - loss: 6.0\n",
      "Epoch 198/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.4646e-06 - accuracy: 0.9954\n",
      "Epoch 199/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.7321e-06 - accuracy: 0.9964\n",
      "Epoch 200/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.2666e-06 - accuracy: 0.9969\n",
      "Epoch 201/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.6593e-06 - accuracy: 0.9958\n",
      "Epoch 202/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.7907e-06 - accuracy: 0.9965\n",
      "Epoch 203/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.7960e-06 - accuracy: 0.9978\n",
      "Epoch 204/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.4446e-05 - accuracy: 0.9962\n",
      "Epoch 205/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 8.7759e-06 - accuracy: 0.9971\n",
      "Epoch 206/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.8011e-06 - accuracy: 0.9965\n",
      "Epoch 207/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.3759e-06 - accuracy: 0.9974\n",
      "Epoch 208/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.2481e-06 - accuracy: 0.9971\n",
      "Epoch 209/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.4171e-06 - accuracy: 0.9973\n",
      "Epoch 210/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.6689e-06 - accuracy: 0.9971\n",
      "Epoch 211/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.8544e-06 - accuracy: 0.9967\n",
      "Epoch 212/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.1304e-06 - accuracy: 0.9967\n",
      "Epoch 213/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.1821e-06 - accuracy: 0.9947\n",
      "Epoch 214/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.5845e-06 - accuracy: 0.9965\n",
      "Epoch 215/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.8664e-06 - accuracy: 0.9964\n",
      "Epoch 216/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.4634e-06 - accuracy: 0.9971\n",
      "Epoch 217/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.6440e-06 - accuracy: 0.9962\n",
      "Epoch 218/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.1170e-06 - accuracy: 0.9969\n",
      "Epoch 219/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3730e-06 - accuracy: 0.9962\n",
      "Epoch 220/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.3552e-06 - accuracy: 0.9967\n",
      "Epoch 221/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.9144e-06 - accuracy: 0.9965\n",
      "Epoch 222/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 7.5125e-06 - accuracy: 0.9964\n",
      "Epoch 223/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 8.5662e-06 - accuracy: 0.9965\n",
      "Epoch 224/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.4557e-06 - accuracy: 0.9980\n",
      "Epoch 225/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.2145e-06 - accuracy: 0.9971\n",
      "Epoch 226/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7508e-06 - accuracy: 0.9971\n",
      "Epoch 227/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.3186e-06 - accuracy: 0.9974\n",
      "Epoch 228/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.5151e-06 - accuracy: 0.9958\n",
      "Epoch 229/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0872e-06 - accuracy: 0.9982\n",
      "Epoch 230/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.3824e-06 - accuracy: 0.9976\n",
      "Epoch 231/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7138e-06 - accuracy: 0.9976\n",
      "Epoch 232/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.2772e-06 - accuracy: 0.9971\n",
      "Epoch 233/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.2891e-06 - accuracy: 0.9956\n",
      "Epoch 234/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.6606e-06 - accuracy: 0.9958: 0s - loss: 4.495\n",
      "Epoch 235/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4940e-06 - accuracy: 0.9973\n",
      "Epoch 236/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4878e-06 - accuracy: 0.9971\n",
      "Epoch 237/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.4502e-06 - accuracy: 0.9971\n",
      "Epoch 238/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7160e-06 - accuracy: 0.9984\n",
      "Epoch 239/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.3208e-06 - accuracy: 0.9949\n",
      "Epoch 240/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.6829e-06 - accuracy: 0.9965\n",
      "Epoch 241/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.2852e-06 - accuracy: 0.9969\n",
      "Epoch 242/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.2123e-06 - accuracy: 0.9982\n",
      "Epoch 243/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.1167e-05 - accuracy: 0.9953\n",
      "Epoch 244/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.9363e-06 - accuracy: 0.9974\n",
      "Epoch 245/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0933e-06 - accuracy: 0.9980\n",
      "Epoch 246/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4460e-06 - accuracy: 0.9964\n",
      "Epoch 247/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.3619e-06 - accuracy: 0.9965\n",
      "Epoch 248/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.5808e-06 - accuracy: 0.9967\n",
      "Epoch 249/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.6996e-06 - accuracy: 0.9987\n",
      "Epoch 250/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.3646e-06 - accuracy: 0.9967\n",
      "Epoch 251/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.0602e-05 - accuracy: 0.9954\n",
      "Epoch 252/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.2075e-06 - accuracy: 0.9969\n",
      "Epoch 253/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.3447e-06 - accuracy: 0.9974\n",
      "Epoch 254/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8081e-06 - accuracy: 0.9984\n",
      "Epoch 255/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.6567e-06 - accuracy: 0.9971\n",
      "Epoch 256/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.3201e-06 - accuracy: 0.9969\n",
      "Epoch 257/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0857e-06 - accuracy: 0.9973\n",
      "Epoch 258/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7107e-06 - accuracy: 0.9976\n",
      "Epoch 259/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.6583e-06 - accuracy: 0.9965\n",
      "Epoch 260/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.5047e-06 - accuracy: 0.9973\n",
      "Epoch 261/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 9.2711e-06 - accuracy: 0.9958\n",
      "Epoch 262/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.1067e-06 - accuracy: 0.9978\n",
      "Epoch 263/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.2117e-06 - accuracy: 0.9978\n",
      "Epoch 264/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 5.8770e-06 - accuracy: 0.9973\n",
      "Epoch 265/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0398e-06 - accuracy: 0.9985\n",
      "Epoch 266/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7549e-06 - accuracy: 0.9973\n",
      "Epoch 267/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0530e-06 - accuracy: 0.9974\n",
      "Epoch 268/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.2046e-06 - accuracy: 0.9964\n",
      "Epoch 269/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.2477e-06 - accuracy: 0.9969\n",
      "Epoch 270/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7921e-06 - accuracy: 0.9973\n",
      "Epoch 271/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4207e-06 - accuracy: 0.9967\n",
      "Epoch 272/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.6016e-06 - accuracy: 0.9962\n",
      "Epoch 273/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.0115e-05 - accuracy: 0.9964\n",
      "Epoch 274/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8190e-06 - accuracy: 0.9967\n",
      "Epoch 275/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.8332e-06 - accuracy: 0.9973\n",
      "Epoch 276/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.0682e-06 - accuracy: 0.9960\n",
      "Epoch 277/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7602e-06 - accuracy: 0.9974\n",
      "Epoch 278/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5706e-06 - accuracy: 0.9978\n",
      "Epoch 279/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.2054e-06 - accuracy: 0.9974\n",
      "Epoch 280/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.2625e-06 - accuracy: 0.9956: 0s - loss: 6.5631e-06 - accu\n",
      "Epoch 281/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3481e-06 - accuracy: 0.9976\n",
      "Epoch 282/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.0636e-06 - accuracy: 0.9967\n",
      "Epoch 283/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.5331e-06 - accuracy: 0.9960\n",
      "Epoch 284/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3374e-06 - accuracy: 0.9980\n",
      "Epoch 285/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0445e-06 - accuracy: 0.9978\n",
      "Epoch 286/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.5544e-06 - accuracy: 0.9974\n",
      "Epoch 287/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.4261e-06 - accuracy: 0.9960\n",
      "Epoch 288/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.9133e-06 - accuracy: 0.9967\n",
      "Epoch 289/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.0698e-06 - accuracy: 0.9985: 0s - loss: 3.0635e-06 - accuracy: 0.99\n",
      "Epoch 290/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.8211e-06 - accuracy: 0.9969\n",
      "Epoch 291/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.2015e-06 - accuracy: 0.9965\n",
      "Epoch 292/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.2322e-06 - accuracy: 0.9969\n",
      "Epoch 293/500\n",
      "343/343 [==============================] - 0s 1ms/step - loss: 3.7525e-06 - accuracy: 0.9967\n",
      "Epoch 294/500\n",
      "343/343 [==============================] - 0s 1ms/step - loss: 2.6494e-06 - accuracy: 0.9978\n",
      "Epoch 295/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3054e-06 - accuracy: 0.9978\n",
      "Epoch 296/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3843e-06 - accuracy: 0.9964\n",
      "Epoch 297/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0992e-06 - accuracy: 0.9967\n",
      "Epoch 298/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8249e-06 - accuracy: 0.9974\n",
      "Epoch 299/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3578e-06 - accuracy: 0.9973\n",
      "Epoch 300/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.4279e-06 - accuracy: 0.9962\n",
      "Epoch 301/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 6.6018e-06 - accuracy: 0.9965\n",
      "Epoch 302/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.2750e-06 - accuracy: 0.9967\n",
      "Epoch 303/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 1s 3ms/step - loss: 3.1160e-06 - accuracy: 0.9984\n",
      "Epoch 304/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.4251e-06 - accuracy: 0.9969\n",
      "Epoch 305/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.5394e-06 - accuracy: 0.9969\n",
      "Epoch 306/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 8.0185e-06 - accuracy: 0.9953\n",
      "Epoch 307/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3650e-06 - accuracy: 0.9978\n",
      "Epoch 308/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.7101e-06 - accuracy: 0.9971\n",
      "Epoch 309/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.1834e-06 - accuracy: 0.9967\n",
      "Epoch 310/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0410e-06 - accuracy: 0.9980\n",
      "Epoch 311/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9944e-06 - accuracy: 0.9978\n",
      "Epoch 312/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.4566e-06 - accuracy: 0.9965\n",
      "Epoch 313/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.0769e-06 - accuracy: 0.9974\n",
      "Epoch 314/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9921e-06 - accuracy: 0.9971\n",
      "Epoch 315/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4728e-06 - accuracy: 0.9969\n",
      "Epoch 316/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0285e-06 - accuracy: 0.9956\n",
      "Epoch 317/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.9218e-06 - accuracy: 0.9969\n",
      "Epoch 318/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8371e-06 - accuracy: 0.9987\n",
      "Epoch 319/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0759e-06 - accuracy: 0.9964\n",
      "Epoch 320/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.8330e-06 - accuracy: 0.9974\n",
      "Epoch 321/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0949e-06 - accuracy: 0.9967\n",
      "Epoch 322/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.2099e-06 - accuracy: 0.9971\n",
      "Epoch 323/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.4272e-06 - accuracy: 0.9969\n",
      "Epoch 324/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4267e-06 - accuracy: 0.9969\n",
      "Epoch 325/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7685e-06 - accuracy: 0.9974\n",
      "Epoch 326/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.1953e-06 - accuracy: 0.9973\n",
      "Epoch 327/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9821e-06 - accuracy: 0.9978\n",
      "Epoch 328/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.8456e-06 - accuracy: 0.9982\n",
      "Epoch 329/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.3507e-06 - accuracy: 0.9962\n",
      "Epoch 330/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.1461e-06 - accuracy: 0.9965\n",
      "Epoch 331/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9560e-06 - accuracy: 0.9985\n",
      "Epoch 332/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5527e-06 - accuracy: 0.9973\n",
      "Epoch 333/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.8440e-06 - accuracy: 0.9976\n",
      "Epoch 334/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3627e-06 - accuracy: 0.9974\n",
      "Epoch 335/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9172e-06 - accuracy: 0.9978\n",
      "Epoch 336/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4246e-06 - accuracy: 0.9980\n",
      "Epoch 337/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.1841e-06 - accuracy: 0.9978\n",
      "Epoch 338/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9710e-06 - accuracy: 0.9985\n",
      "Epoch 339/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.1158e-06 - accuracy: 0.9969\n",
      "Epoch 340/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0754e-06 - accuracy: 0.9980\n",
      "Epoch 341/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9678e-06 - accuracy: 0.9971\n",
      "Epoch 342/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7381e-06 - accuracy: 0.9964\n",
      "Epoch 343/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.2532e-06 - accuracy: 0.9976\n",
      "Epoch 344/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.1185e-06 - accuracy: 0.9964\n",
      "Epoch 345/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.2802e-06 - accuracy: 0.9958\n",
      "Epoch 346/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.1211e-06 - accuracy: 0.9969\n",
      "Epoch 347/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8496e-06 - accuracy: 0.9985\n",
      "Epoch 348/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.1866e-06 - accuracy: 0.9964\n",
      "Epoch 349/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1243e-06 - accuracy: 0.9976\n",
      "Epoch 350/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2603e-06 - accuracy: 0.9973\n",
      "Epoch 351/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3637e-06 - accuracy: 0.9980\n",
      "Epoch 352/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.7730e-06 - accuracy: 0.9967\n",
      "Epoch 353/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1870e-06 - accuracy: 0.9974\n",
      "Epoch 354/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0952e-06 - accuracy: 0.9980\n",
      "Epoch 355/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.7490e-06 - accuracy: 0.9980\n",
      "Epoch 356/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.9677e-06 - accuracy: 0.9973\n",
      "Epoch 357/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0633e-06 - accuracy: 0.9974\n",
      "Epoch 358/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1167e-06 - accuracy: 0.9974\n",
      "Epoch 359/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8093e-06 - accuracy: 0.9976\n",
      "Epoch 360/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7282e-06 - accuracy: 0.9976\n",
      "Epoch 361/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.0962e-06 - accuracy: 0.9965\n",
      "Epoch 362/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7268e-06 - accuracy: 0.9965\n",
      "Epoch 363/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5877e-06 - accuracy: 0.9967\n",
      "Epoch 364/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.2361e-06 - accuracy: 0.9969\n",
      "Epoch 365/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2629e-06 - accuracy: 0.9985\n",
      "Epoch 366/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0144e-06 - accuracy: 0.9967\n",
      "Epoch 367/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9687e-06 - accuracy: 0.9985\n",
      "Epoch 368/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.4454e-06 - accuracy: 0.9980\n",
      "Epoch 369/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8878e-06 - accuracy: 0.9980\n",
      "Epoch 370/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4386e-06 - accuracy: 0.9980\n",
      "Epoch 371/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.7687e-06 - accuracy: 0.9978\n",
      "Epoch 372/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4001e-06 - accuracy: 0.9978\n",
      "Epoch 373/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.9634e-06 - accuracy: 0.9960\n",
      "Epoch 374/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4411e-06 - accuracy: 0.9976\n",
      "Epoch 375/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5220e-06 - accuracy: 0.9978\n",
      "Epoch 376/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.5965e-06 - accuracy: 0.9969\n",
      "Epoch 377/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2740e-06 - accuracy: 0.9973\n",
      "Epoch 378/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9749e-06 - accuracy: 0.9985\n",
      "Epoch 379/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7373e-06 - accuracy: 0.9965\n",
      "Epoch 380/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.4762e-06 - accuracy: 0.9976\n",
      "Epoch 381/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4219e-06 - accuracy: 0.9978\n",
      "Epoch 382/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7020e-06 - accuracy: 0.9967\n",
      "Epoch 383/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.2686e-06 - accuracy: 0.9965\n",
      "Epoch 384/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2823e-06 - accuracy: 0.9974\n",
      "Epoch 385/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0589e-06 - accuracy: 0.9976\n",
      "Epoch 386/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.5089e-06 - accuracy: 0.9969\n",
      "Epoch 387/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3171e-06 - accuracy: 0.9974\n",
      "Epoch 388/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4001e-06 - accuracy: 0.9984\n",
      "Epoch 389/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.6980e-06 - accuracy: 0.9989\n",
      "Epoch 390/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3455e-06 - accuracy: 0.9980\n",
      "Epoch 391/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.8851e-06 - accuracy: 0.9982\n",
      "Epoch 392/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.0890e-06 - accuracy: 0.9980\n",
      "Epoch 393/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0876e-06 - accuracy: 0.9971\n",
      "Epoch 394/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.4539e-06 - accuracy: 0.9971\n",
      "Epoch 395/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.8587e-06 - accuracy: 0.9980\n",
      "Epoch 396/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5928e-06 - accuracy: 0.9982\n",
      "Epoch 397/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7831e-06 - accuracy: 0.9982\n",
      "Epoch 398/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0725e-06 - accuracy: 0.9982\n",
      "Epoch 399/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3414e-06 - accuracy: 0.9974\n",
      "Epoch 400/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.9099e-06 - accuracy: 0.9980\n",
      "Epoch 401/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9296e-06 - accuracy: 0.9967\n",
      "Epoch 402/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.6235e-06 - accuracy: 0.9982\n",
      "Epoch 403/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 4.2919e-06 - accuracy: 0.9971\n",
      "Epoch 404/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.0067e-06 - accuracy: 0.9960\n",
      "Epoch 405/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.4612e-06 - accuracy: 0.9978\n",
      "Epoch 406/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.2245e-06 - accuracy: 0.9969\n",
      "Epoch 407/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.1094e-06 - accuracy: 0.9980\n",
      "Epoch 408/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.5289e-06 - accuracy: 0.9967\n",
      "Epoch 409/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9657e-06 - accuracy: 0.9965\n",
      "Epoch 410/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.6107e-06 - accuracy: 0.9987\n",
      "Epoch 411/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.3222e-06 - accuracy: 0.9969\n",
      "Epoch 412/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.5981e-06 - accuracy: 0.9978\n",
      "Epoch 413/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5120e-06 - accuracy: 0.9978\n",
      "Epoch 414/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1157e-06 - accuracy: 0.9976\n",
      "Epoch 415/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3365e-06 - accuracy: 0.9976\n",
      "Epoch 416/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2757e-06 - accuracy: 0.9989\n",
      "Epoch 417/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 7.1968e-06 - accuracy: 0.9976\n",
      "Epoch 418/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.3631e-06 - accuracy: 0.9982\n",
      "Epoch 419/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.8881e-06 - accuracy: 0.9976\n",
      "Epoch 420/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7783e-06 - accuracy: 0.9974\n",
      "Epoch 421/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.7070e-06 - accuracy: 0.9978\n",
      "Epoch 422/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.6569e-06 - accuracy: 0.9976\n",
      "Epoch 423/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.9828e-06 - accuracy: 0.9978\n",
      "Epoch 424/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3248e-06 - accuracy: 0.9974\n",
      "Epoch 425/500\n",
      "343/343 [==============================] - ETA: 0s - loss: 4.3589e-06 - accuracy: 0.99 - 1s 3ms/step - loss: 4.3636e-06 - accuracy: 0.9967\n",
      "Epoch 426/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7741e-06 - accuracy: 0.9965\n",
      "Epoch 427/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.4057e-06 - accuracy: 0.9973\n",
      "Epoch 428/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9910e-06 - accuracy: 0.9976\n",
      "Epoch 429/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4234e-06 - accuracy: 0.9974\n",
      "Epoch 430/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.7511e-06 - accuracy: 0.9965\n",
      "Epoch 431/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3050e-06 - accuracy: 0.9976\n",
      "Epoch 432/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7046e-06 - accuracy: 0.9965\n",
      "Epoch 433/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9428e-06 - accuracy: 0.9982\n",
      "Epoch 434/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9646e-06 - accuracy: 0.9967\n",
      "Epoch 435/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8013e-06 - accuracy: 0.9965\n",
      "Epoch 436/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8559e-06 - accuracy: 0.9985\n",
      "Epoch 437/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5382e-06 - accuracy: 0.9976\n",
      "Epoch 438/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.2783e-06 - accuracy: 0.9965\n",
      "Epoch 439/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.5796e-06 - accuracy: 0.9982\n",
      "Epoch 440/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.1962e-06 - accuracy: 0.9974\n",
      "Epoch 441/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.1676e-06 - accuracy: 0.9969\n",
      "Epoch 442/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.7641e-06 - accuracy: 0.9978\n",
      "Epoch 443/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.8187e-06 - accuracy: 0.9969\n",
      "Epoch 444/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3182e-06 - accuracy: 0.9974\n",
      "Epoch 445/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4342e-06 - accuracy: 0.9987\n",
      "Epoch 446/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.1152e-06 - accuracy: 0.9984\n",
      "Epoch 447/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1721e-06 - accuracy: 0.9973\n",
      "Epoch 448/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 6.8386e-06 - accuracy: 0.9969\n",
      "Epoch 449/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5455e-06 - accuracy: 0.9976\n",
      "Epoch 450/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8647e-06 - accuracy: 0.9984\n",
      "Epoch 451/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.6049e-06 - accuracy: 0.9985\n",
      "Epoch 452/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1105e-06 - accuracy: 0.9971\n",
      "Epoch 453/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1606e-06 - accuracy: 0.9984\n",
      "Epoch 454/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.1098e-06 - accuracy: 0.9984\n",
      "Epoch 455/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3507e-06 - accuracy: 0.9969\n",
      "Epoch 456/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.6195e-06 - accuracy: 0.9982\n",
      "Epoch 457/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2866e-06 - accuracy: 0.9971\n",
      "Epoch 458/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.9864e-06 - accuracy: 0.9969\n",
      "Epoch 459/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.8075e-06 - accuracy: 0.9971\n",
      "Epoch 460/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5046e-06 - accuracy: 0.9971\n",
      "Epoch 461/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3257e-06 - accuracy: 0.9969\n",
      "Epoch 462/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 1.8057e-06 - accuracy: 0.9985\n",
      "Epoch 463/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4033e-06 - accuracy: 0.9978\n",
      "Epoch 464/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7335e-06 - accuracy: 0.9985\n",
      "Epoch 465/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.0755e-06 - accuracy: 0.9974\n",
      "Epoch 466/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8295e-06 - accuracy: 0.9980\n",
      "Epoch 467/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3245e-06 - accuracy: 0.9971\n",
      "Epoch 468/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.2759e-06 - accuracy: 0.9974\n",
      "Epoch 469/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.7966e-06 - accuracy: 0.9978: 0s - loss: 1.7863e-06 - accuracy: \n",
      "Epoch 470/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8201e-06 - accuracy: 0.9978\n",
      "Epoch 471/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.0587e-06 - accuracy: 0.9978\n",
      "Epoch 472/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.9216e-06 - accuracy: 0.9974\n",
      "Epoch 473/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.0208e-06 - accuracy: 0.9978\n",
      "Epoch 474/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.0506e-06 - accuracy: 0.9973\n",
      "Epoch 475/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.8261e-06 - accuracy: 0.9965\n",
      "Epoch 476/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.3507e-06 - accuracy: 0.9982\n",
      "Epoch 477/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 5.3641e-06 - accuracy: 0.9960\n",
      "Epoch 478/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3310e-06 - accuracy: 0.9976\n",
      "Epoch 479/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3994e-06 - accuracy: 0.9969: 0s - loss: 2.6123e-06 - ac\n",
      "Epoch 480/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9793e-06 - accuracy: 0.9984\n",
      "Epoch 481/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2081e-06 - accuracy: 0.9989\n",
      "Epoch 482/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.5772e-06 - accuracy: 0.9964\n",
      "Epoch 483/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.3199e-06 - accuracy: 0.9980\n",
      "Epoch 484/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.1708e-06 - accuracy: 0.9982\n",
      "Epoch 485/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.7210e-06 - accuracy: 0.9980\n",
      "Epoch 486/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 2.4809e-06 - accuracy: 0.9980\n",
      "Epoch 487/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.3067e-06 - accuracy: 0.9976\n",
      "Epoch 488/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.0012e-06 - accuracy: 0.9974\n",
      "Epoch 489/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.9865e-06 - accuracy: 0.9987\n",
      "Epoch 490/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.8631e-06 - accuracy: 0.9969\n",
      "Epoch 491/500\n",
      "343/343 [==============================] - 1s 3ms/step - loss: 3.1961e-06 - accuracy: 0.9971\n",
      "Epoch 492/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.4150e-06 - accuracy: 0.9973\n",
      "Epoch 493/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.4547e-06 - accuracy: 0.9980\n",
      "Epoch 494/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.0194e-06 - accuracy: 0.9974\n",
      "Epoch 495/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.7420e-06 - accuracy: 0.9978\n",
      "Epoch 496/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 3.2393e-06 - accuracy: 0.9978\n",
      "Epoch 497/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.5743e-06 - accuracy: 0.9976\n",
      "Epoch 498/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 1.8658e-06 - accuracy: 0.9971\n",
      "Epoch 499/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 4.9125e-06 - accuracy: 0.9985\n",
      "Epoch 500/500\n",
      "343/343 [==============================] - 1s 2ms/step - loss: 2.2365e-06 - accuracy: 0.9969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2c79dcdd788>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_training, y_training, epochs=500, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/43 [==============================] - 0s 1ms/step - loss: 7.2364e-06 - accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "#評估模型 loss & accuracy\n",
    "loss_metrics = model.evaluate(x_testing, y_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[round(i, 5) for i in loss_metrics]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用測試集進行預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = model.predict(x_testing) #.reshape(npy_test.shape[0],npy_test.shape[1])\n",
    "#numpy 列合併\n",
    "pred1 = np.column_stack((pred0, y_testing))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將測試的集預測值還原"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.23907102 -0.28172951  8.24264728 -0.28285123]\n",
      " [13.45968741  0.20934006 13.49651103  0.21025867]\n",
      " [12.05619002  0.0553987  12.07624554  0.05339629]\n",
      " ...\n",
      " [17.92706462  0.12569643 17.98507311  0.12706249]\n",
      " [ 3.332576   -0.15369529  3.45638018 -0.16179619]\n",
      " [12.18556611  0.54087814 12.15723378  0.54303634]]\n"
     ]
    }
   ],
   "source": [
    "re_pred1 = testy.inverse_transform(pred1[:,:-2]) #前兩行(到第三欄前的都要)(預測值)\n",
    "re_pred2 = testy.inverse_transform(pred1[:,2:]) #後兩行(從第三欄後的到最後都要)(實際值)\n",
    "re_pred = np.column_stack((re_pred1, re_pred2))\n",
    "print(re_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RMSE\n",
    "def rmse(predict, actual):\n",
    "    return np.sqrt(((predict - actual) ** 2).mean())\n",
    "#MAPE\n",
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true))*100\n",
    "#SMAPE\n",
    "def smape(actual, predict):\n",
    "    return 1/len(actual) * np.sum(2 * np.abs(predict-actual) / (np.abs(actual) + np.abs(predict))*100)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "#r2_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2_H2O： 0.999682325601027 \n",
      "RMSE_H2O： 0.16033728479266604 \n",
      "MAPE_H2O： 0.5839023541538656 % \n",
      "--------------------------- \n",
      "R^2_PH： 0.9999519892346866 \n",
      "RMSE_PH： 0.002440352311850585 \n",
      "MAPE_PH： 1.732060244706372 %\n"
     ]
    }
   ],
   "source": [
    "#H2O的RMSE\n",
    "rmse_H2O = rmse(re_pred[:,0].reshape(re_pred.shape[0],1), re_pred[:,2].reshape(re_pred.shape[0],1))\n",
    "#PH的RMSE\n",
    "rmse_PH = rmse(re_pred[:,1].reshape(re_pred.shape[0],1), re_pred[:,3].reshape(re_pred.shape[0],1))\n",
    "\n",
    "#H2O的MAPE\n",
    "mape_H2O = mape(re_pred[:,2].reshape(re_pred.shape[0],1), re_pred[:,0].reshape(re_pred.shape[0],1))\n",
    "#PH的MAPE\n",
    "mape_PH = mape(re_pred[:,3].reshape(re_pred.shape[0],1), re_pred[:,1].reshape(re_pred.shape[0],1))\n",
    "\n",
    "# #Y1的SMAPE\n",
    "# smapeY1 = smape(pred1[:,2].reshape(pred1.shape[0],1), pred1[:,0].reshape(pred1.shape[0],1))\n",
    "# #Y2的SMAPE\n",
    "# smapeY2 = smape(pred1[:,3].reshape(pred1.shape[0],1), pred1[:,1].reshape(pred1.shape[0],1))\n",
    "\n",
    "print('R^2_H2O：' ,r2_score(re_pred[:,2].reshape(re_pred.shape[0],1), re_pred[:,0].reshape(re_pred.shape[0],1)),\"\\n\"\n",
    "      'RMSE_H2O：' ,rmse_H2O,\"\\n\"\n",
    "      'MAPE_H2O：' ,mape_H2O,\"%\",\"\\n\"\n",
    "      '---------------------------',\"\\n\"\n",
    "      'R^2_PH：',r2_score(re_pred[:,3].reshape(re_pred.shape[0],1), re_pred[:,1].reshape(re_pred.shape[0],1)), \"\\n\"\n",
    "      'RMSE_PH：' ,rmse_PH,\"\\n\"\n",
    "      'MAPE_PH：',mape_PH,\"%\")\n",
    "\n",
    "# print(rmse_H2O, rmse_PH, mape_H2O, mape_PH, \n",
    "#       r2_score(re_pred[:,2].reshape(re_pred.shape[0],1), re_pred[:,0].reshape(re_pred.shape[0],1)),\n",
    "#       r2_score(re_pred[:,3].reshape(re_pred.shape[0],1), re_pred[:,1].reshape(re_pred.shape[0],1)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras模型只能使用HDF5(.h5)的儲存方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/AI-model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #讀取.h5的格式檔案\n",
    "# import tensorflow as tf\n",
    "# reload_model = tf.keras.models.load_model('C:/Users/bigje/Desktop/keras_model.h5')\n",
    "# #查看load下來的檔案\n",
    "# reload_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ※※※※※※※※※※※※※※※※※※※※"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI model-2(API 581)-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#先把mpy.csv的data匯入，使用numpy矩陣型態\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "np.set_printoptions(suppress=True)\n",
    "mpy1 = pd.read_csv('C:/Users/bigje/Desktop/FCFC-chem1/mpy(1).csv',\n",
    "                 index_col=0,\n",
    "                 parse_dates=True,\n",
    "                 encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpy1\n",
    "mpy2 = mpy1.to_numpy() #轉成np格式\n",
    "# type(mpy2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API 581為training data\n",
    "#目標欄需為整數，因為是分群(分類)問題\n",
    "X_train = mpy2[:,0:2]\n",
    "y_train = mpy2[:,2]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn's KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=2) #分2群\n",
    "knn1 = knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存成pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/bigje/Desktop/AI-model2.pkl']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(knn1, 'C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/AI-model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #讀取pkl\n",
    "# knn2 = joblib.load('C:/Users/bigje/Desktop/AI-model2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ※※※※※※※※※※※※※※※※※※※※"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新數據進行串接-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5個inputs(feed,H2O,HCI,LPG,C4) 跟各管段溫度可自行輸入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "入料量：170\n",
      "含水量：50\n",
      "含氯量：1\n",
      "LPG：0.001\n",
      "C4：0.001\n",
      "管段1溫度：68.2\n",
      "管段2溫度：55\n",
      "管段3,4溫度：44.3\n",
      "-----\n",
      "管段1-PH：[-0.5026866]\n",
      "管段1-H2O：[14.915763]\n",
      "管段1-alpha：[0.01031]\n",
      "管段1-corrosion：[25.37]\n",
      "管段1-correction_corrosion：[0.2615647]\n",
      "-----\n",
      "管段2-PH：[-0.5026866]\n",
      "管段2-H2O：[14.915763]\n",
      "管段2-alpha：[0.01304]\n",
      "管段2-corrosion：[25.37]\n",
      "管段2-correction_corrosion：[0.33082479]\n",
      "-----\n",
      "管段3-PH：[-0.5026866]\n",
      "管段3-H2O：[14.915763]\n",
      "管段3-alpha：[0.0112]\n",
      "管段3-corrosion：[25.37]\n",
      "管段3-correction_corrosion：[0.28414399]\n",
      "-----\n",
      "管段4-PH：[-0.5026866]\n",
      "管段4-H2O：[14.915763]\n",
      "管段4-alpha：[0.01165]\n",
      "管段4-corrosion：[25.37]\n",
      "管段4-correction_corrosion：[0.29556049]\n",
      "-----\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "Input_data = dict({\n",
    "    '3C250_feed': float(input('入料量：')),\n",
    "    '3C250_H2O': float(input('含水量：')),\n",
    "    '3C250_HCL': float(input('含氯量：')),\n",
    "    'LPG': float(input('LPG：')),\n",
    "    'C4': float(input('C4：')),\n",
    "    '3C250_temp': float(input('管段1溫度：')),  #管段1  溫度\n",
    "    '3E254_temp': float(input('管段2溫度：')),   #管段2  溫度\n",
    "    '3E255_temp': float(input('管段3,4溫度：')),  #管段34 溫度\n",
    "})\n",
    "#儲存input data的數值於numpy格式\n",
    "xxtest =np.array([[Input_data['3C250_feed'], Input_data['3C250_H2O'], Input_data['3C250_HCL'], Input_data['LPG'], \n",
    "                   Input_data['C4']]])\n",
    "#匯入AI模型1跟2的.h5&.pkl檔\n",
    "AI_model1 = tf.keras.models.load_model('C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/AI-model1.h5')\n",
    "AI_model2 = joblib.load('C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/AI-model2.pkl')\n",
    "#導入自變數與依變數的原檔(.pkl)\n",
    "npx_train = joblib.load('C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/minmax-x.pkl')\n",
    "npy_train = joblib.load('C:/Users/bigje/Desktop/FCFC-chem1/Corrosion_rate_model/minmax-y.pkl')\n",
    "#------------------------------------------------------------------------------------------------------------------#\n",
    "#正規化input data，以便AI model1使用\n",
    "#feed\n",
    "def nx1(feed):\n",
    "    return  (feed - npx_train[:,0].min()) / (npx_train[:,0].max()-npx_train[:,0].min())\n",
    "#H2O\n",
    "def nx2(H2O):\n",
    "    return  (H2O - npx_train[:,1].min()) / (npx_train[:,1].max()-npx_train[:,1].min())\n",
    "#HCL\n",
    "def nx3(HCL):\n",
    "    return  (HCL - npx_train[:,2].min()) / (npx_train[:,2].max()-npx_train[:,2].min())\n",
    "#LPG\n",
    "def nx4(LPG):\n",
    "    return  (LPG - npx_train[:,3].min()) / (npx_train[:,3].max()-npx_train[:,3].min())\n",
    "#C4\n",
    "def nx5(C4):\n",
    "    return  (C4 - npx_train[:,4].min()) / (npx_train[:,4].max()-npx_train[:,4].min())\n",
    "#H2O-float\n",
    "def ny1(H2O_float):\n",
    "    return  (H2O_float * (npy_train[:,0].max() - npy_train[:,0].min()) + npy_train[:,0].min() )\n",
    "#pH\n",
    "def ny2(pH):\n",
    "    return  (pH * (npy_train[:,1].max() - npy_train[:,1].min()) + npy_train[:,1].min() )\n",
    "#整理全部的輸入變數\n",
    "n1 = nx1(xxtest[:,0])\n",
    "n2 = nx2(xxtest[:,1])\n",
    "n3 = nx3(xxtest[:,2])\n",
    "n4 = nx4(xxtest[:,3])\n",
    "n5 = nx5(xxtest[:,4])\n",
    "#合併\n",
    "xxtesting = np.column_stack((n1,n2,n3,n4,n5))\n",
    "\n",
    "#進入AI model1預測\n",
    "xxpred0 = AI_model1.predict(xxtesting) #.reshape(npy_test.shape[0],npy_test.shape[1])\n",
    "#預測值還原\n",
    "xxy1 = ny1(xxpred0[:,0])\n",
    "xxy2 = ny2(xxpred0[:,1])\n",
    "re_pred0 = np.column_stack((xxy1,xxy2))\n",
    "#------------------------------------------------------------------------------------------------------------------#\n",
    "#操作溫度與pH預測值合併\n",
    "ne1 = np.c_[Input_data['3C250_temp'],re_pred0[:,1]]\n",
    "ne2 = np.c_[Input_data['3E254_temp'],re_pred0[:,1]]\n",
    "ne34 = np.c_[Input_data['3E255_temp'],re_pred0[:,1]]\n",
    "\n",
    "#進入AI model2預測腐蝕率(beta)\n",
    "pred1 = AI_model2.predict(ne1)\n",
    "pred2 = AI_model2.predict(ne2)\n",
    "pred34 = AI_model2. predict(ne34)\n",
    "beta1 = pred1/100\n",
    "beta2 = pred2/100\n",
    "beta34 = pred34/100\n",
    "#------------------------------------------------------------------------------------------------------------------#\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "su1 = pd.read_excel('C:/Users/bigje/Desktop/FCFC-chem1/修正係數/新修正係數.xlsx', skiprows = 2, sheet_name = None)\n",
    "su = su1.get('Corrosion')     #修正係數表單區\n",
    "rate = su1.get('Interaction') #層厚影響的佔水比例表單\n",
    "suw = su.columns[6]           #水膜厚度\n",
    "su.columns = ['X','Section','x1','x2','x3','x4','x5','x6','x7','x8','alpha']\n",
    "\n",
    "rate1 = rate.to_numpy()\n",
    "rate1 = rate1[8:12,8]        #層厚影響的佔水比例\n",
    "su = su.to_numpy()\n",
    "su_x4_sum = su[1:5,5].sum()  #各管段內部容積*各管段真實密度之總和\n",
    "\n",
    "#各管段的修正係數公式(輸入H2O預測值，x1)\n",
    "def section1(x1):\n",
    "    return ((((x1/su_x4_sum*su[1,5])*rate1[0])*1000/suw/10000)/su[1,2])*2\n",
    "def section2(x1):\n",
    "    return ((((x1/su_x4_sum*su[2,5])*rate1[1])*1000/suw/10000)/su[2,2])*2\n",
    "def section3(x1):\n",
    "    return ((((x1/su_x4_sum*su[3,5])*rate1[2])*1000/suw/10000)/su[3,2])*2\n",
    "def section4(x1):\n",
    "    return ((((x1/su_x4_sum*su[4,5])*rate1[3])*1000/suw/10000)/su[4,2])*2\n",
    "#各管段修正係數(alpha)\n",
    "s1alpha = np.around(section1(re_pred0[:,0]),5)\n",
    "s2alpha = np.around(section2(re_pred0[:,0]),5)\n",
    "s3alpha = np.around(section3(re_pred0[:,0]),5)\n",
    "s4alpha = np.around(section4(re_pred0[:,0]),5)\n",
    "# print(f's1alpha：{s1alpha}\\ns2alpha：{s2alpha}\\ns3alpha：{s3alpha}\\ns4alpha：{s4alpha}')\n",
    "#------------------------------------------------------------------------------------------------------------------#\n",
    "#修正後腐蝕率\n",
    "CR1 = beta1 * s1alpha\n",
    "CR2 = beta2 * s2alpha\n",
    "CR3 = beta34 * s3alpha\n",
    "CR4 = beta34 * s4alpha\n",
    "#------------------------------------------------------------------------------------------------------------------#\n",
    "#將所有輸出結果存在字典裡\n",
    "model_pred = dict({\n",
    "    '3V256_3C250': dict({\n",
    "        'PH': re_pred0[:,1],\n",
    "        'H2O': re_pred0[:,0],\n",
    "        'alpha': s1alpha,\n",
    "        'corrosion': beta1,\n",
    "        'correction_corrosion': CR1,\n",
    "    }),\n",
    "    '3C250_3E254': dict({\n",
    "        'PH': re_pred0[:,1],\n",
    "        'H2O': re_pred0[:,0],\n",
    "        'alpha': s2alpha,\n",
    "        'corrosion': beta2,\n",
    "        'correction_corrosion': CR2,\n",
    "    }),\n",
    "    '3E254_3E255': dict({\n",
    "        'PH': re_pred0[:,1],\n",
    "        'H2O': re_pred0[:,0],\n",
    "        'alpha': s3alpha,\n",
    "        'corrosion': beta34,\n",
    "        'correction_corrosion': CR3,\n",
    "    }),\n",
    "    '3E255_2V256': dict({\n",
    "        'PH': re_pred0[:,1],\n",
    "        'H2O': re_pred0[:,0],\n",
    "        'alpha': s4alpha,\n",
    "        'corrosion': beta34,\n",
    "        'correction_corrosion': CR4,\n",
    "    }),\n",
    "    \n",
    "})\n",
    "print(f\"-----\\n管段1-PH：{model_pred['3V256_3C250']['PH']}\\n管段1-H2O：{model_pred['3V256_3C250']['H2O']}\\n管段1-alpha：{model_pred['3V256_3C250']['alpha']}\\n管段1-corrosion：{model_pred['3V256_3C250']['corrosion']}\\n管段1-correction_corrosion：{model_pred['3V256_3C250']['correction_corrosion']}\\n-----\")\n",
    "print(f\"管段2-PH：{model_pred['3C250_3E254']['PH']}\\n管段2-H2O：{model_pred['3C250_3E254']['H2O']}\\n管段2-alpha：{model_pred['3C250_3E254']['alpha']}\\n管段2-corrosion：{model_pred['3C250_3E254']['corrosion']}\\n管段2-correction_corrosion：{model_pred['3C250_3E254']['correction_corrosion']}\\n-----\")\n",
    "print(f\"管段3-PH：{model_pred['3E254_3E255']['PH']}\\n管段3-H2O：{model_pred['3E254_3E255']['H2O']}\\n管段3-alpha：{model_pred['3E254_3E255']['alpha']}\\n管段3-corrosion：{model_pred['3E254_3E255']['corrosion']}\\n管段3-correction_corrosion：{model_pred['3E254_3E255']['correction_corrosion']}\\n-----\")\n",
    "print(f\"管段4-PH：{model_pred['3E255_2V256']['PH']}\\n管段4-H2O：{model_pred['3E255_2V256']['H2O']}\\n管段4-alpha：{model_pred['3E255_2V256']['alpha']}\\n管段4-corrosion：{model_pred['3E255_2V256']['corrosion']}\\n管段4-correction_corrosion：{model_pred['3E255_2V256']['correction_corrosion']}\\n-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
